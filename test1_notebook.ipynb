{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import TreebankWordTokenizer\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, LSTM, Lambda\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import Input\n",
    "from keras.layers import concatenate\n",
    "\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')[['question1', 'question2', 'is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.arrange(df.shape[0])\n",
    "#indices.tolist()\n",
    "#np.random.shuffle(indices)\n",
    "data_a = df['question1']#.tolist()\n",
    "data_b = df['question2']#.tolist()\n",
    "label = df['is_duplicate']#.tolist()\n",
    "#data_a = data_a[indices]\n",
    "#data_b = data_b[indices]\n",
    "#label = label[indices]\n",
    "#data_a[indices]\n",
    "train_sample = 60000\n",
    "val_sample = 60000\n",
    "train_a = data_a[:train_sample]\n",
    "train_b = data_b[:train_sample]\n",
    "train_label = label[:train_sample]\n",
    "val_a = data_a[train_sample:train_sample+val_sample]\n",
    "val_b = data_b[train_sample:train_sample+val_sample]\n",
    "val_label = label[train_sample:train_sample+val_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = '/home/ubuntu/ml_nlp/glove_d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.50d.txt'), encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coeff = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings[word]=coeff\n",
    "f.close()\n",
    "#return embedding\n",
    "#print('Found %s word vectors.' % len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in embeddings:\n",
    "        return embeddings[word]\n",
    " \n",
    "tokenizer = TreebankWordTokenizer()\n",
    "def vectorise_sentence(sentence):\n",
    "    #if type(sentence) == 'str':\n",
    "        #tokens = word_tokenize(sentence)\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        vector = []\n",
    "        for token in tokens:\n",
    "            if token not in string.punctuation:\n",
    "                token_vector = get_vector(token)\n",
    "                if token_vector is not None:\n",
    "                    vector.append(token_vector)\n",
    "        return vector\n",
    "\n",
    "def vectorize_df(dfa):\n",
    "     vectorsa = [vectorise_sentence(sentence) for sentence in dfa]   \n",
    "     return vectorsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_b1 = val_b[val_b.notnull()]\n",
    "val_a1 = val_a[val_b.notnull()]\n",
    "val_label1 = val_label[val_b.notnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_b1 = val_b[val_b.notnull()]\n",
    "val_a1 = val_a[val_b.notnull()]\n",
    "val_label1 = val_label[val_b.notnull()]\n",
    "\n",
    "val_a1.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_a_vectors = vectorize_df(val_a1)\n",
    "val_b_vectors = vectorize_df(val_b1)\n",
    "val_scores = val_label1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_vectors = vectorize_df(train_a)\n",
    "train_b_vectors = vectorize_df(train_b)\n",
    "train_scores = train_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_a_length = len(max(train_a_vectors, key=len))\n",
    "train_max_b_length = len(max(train_b_vectors, key=len))\n",
    "val_max_a_length = len(max(val_a_vectors, key=len))\n",
    "val_max_b_length = len(max(val_b_vectors, key=len))\n",
    "max_len = max([train_max_a_length, train_max_b_length,val_max_a_length, val_max_b_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_vectors = pad_sequences(train_a_vectors, padding='post', dtype='float32', maxlen=max_len)\n",
    "train_b_vectors = pad_sequences(train_b_vectors, padding='post', dtype='float32', maxlen=max_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.45 GiB for an array with shape (59999, 219, 50) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-122bdb52a259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_a_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_a_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_b_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_b_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     81\u001b[0m                          .format(dtype, type(value)))\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.45 GiB for an array with shape (59999, 219, 50) and data type float32"
     ]
    }
   ],
   "source": [
    "val_a_vectors = pad_sequences(val_a_vectors, padding='post', dtype='float32', maxlen=max_len)\n",
    "val_b_vectors = pad_sequences(val_b_vectors, padding='post', dtype='float32', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 50\n",
    "h_units = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 50 #50\n",
    "h_units = 100\n",
    "n_hidden = 50\n",
    "\n",
    "lstm = layers.LSTM(n_hidden, unit_forget_bias=True, \n",
    "                               kernel_initializer='he_normal',\n",
    "                               kernel_regularizer='l2',\n",
    "                               name='lstm_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = Input(shape=(None, input_dim), name='input_1')\n",
    "#        left_masked_input = layers.Masking(mask_value=0)(left_input)\n",
    "left_output = lstm(left_input)\n",
    "right_input = Input(shape=(None, input_dim), name='input_2')\n",
    "#        right_masked_input = layers.Masking(mask_value=0)(right_input)\n",
    "right_output = lstm(right_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_norm = lambda x: 1 - K.abs(x[0] - x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = layers.Lambda(function=l1_norm, output_shape=lambda x: x[0], \n",
    "                               name='L1_distance')([left_output, right_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = layers.Dense(1, activation='sigmoid', name='Similarity_layer')(merged)\n",
    "model = Model([left_input, right_input], predictions)\n",
    "optimizer = Adadelta()\n",
    "model.compile(loss = 'mse', optimizer = optimizer, metrics=['accuracy'])\n",
    "history = model.fit([train_a_vectors, train_b_vectors], train_scores, batch_size=64, nb_epoch=5,\n",
    "                            validation_data=([val_a_vectors, val_b_vectors], val_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 50\n",
    "gradient_clipping_norm = 0.25\n",
    "batch_size = 64\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = Input(shape=(max_len,input_dim))\n",
    "right_input = Input(shape=(max_len,input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a79ee60d0c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Embedded version of the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoded_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mencoded_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0;31m# Load weights that were specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m                 raise ValueError('Layer weight shape ' +\n\u001b[1;32m   1124\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "embedding_dim = input_dim\n",
    "\n",
    "embedding_layer = Embedding(max_len, embedding_dim, weights=[embeddings], trainable=False)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_input =Input(shape=(None, input_dim), name='input_1')\n",
    "left_output = lstm(right_input)\n",
    "    \n",
    "#right_input =Input(shape=(None, input_dim), name='input_2')\n",
    "right_output = lstm(right_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "malstm = Model([left_input, right_input], [malstm_distance])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adadelta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "training_start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f377c1f6da0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f378241e240>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1256, in unstack\n",
      "    return self._implementation.unstack(value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f378241ecf8>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1256, in unstack\n",
      "    return self._implementation.unstack(value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 351, in unstack\n",
      "    indices=math_ops.range(0, num_elements), value=value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f3783102d68>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f378311f080>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1256, in unstack\n",
      "    return self._implementation.unstack(value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f378311fe10>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1256, in unstack\n",
      "    return self._implementation.unstack(value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 351, in unstack\n",
      "    indices=math_ops.range(0, num_elements), value=value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f3782cffcc0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f3782cffe10>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1256, in unstack\n",
      "    return self._implementation.unstack(value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f3782cffe80>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3722, in <genexpr>\n",
      "    for ta, input_ in zip(input_ta, flatted_inputs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1256, in unstack\n",
      "    return self._implementation.unstack(value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 351, in unstack\n",
      "    indices=math_ops.range(0, num_elements), value=value, name=name)  File \"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 40000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      " 8512/40000 [=====>........................] - ETA: 50s - loss: 0.6217 - accuracy: 0.3783"
     ]
    }
   ],
   "source": [
    "\n",
    "malstm_trained = malstm.fit([train_a_vectors, train_b_vectors], train_scores, batch_size=batch_size, nb_epoch=n_epoch,\n",
    "                            validation_data=([val_a_vectors, val_b_vectors], val_scores))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time finished.\n",
      "5 epochs in 0:13:21.904000\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.627832556610601,\n",
       "  0.627832556610601,\n",
       "  0.627832556610601,\n",
       "  0.627832556610601,\n",
       "  0.627832556610601],\n",
       " 'val_accuracy': [0.3721674382686615,\n",
       "  0.3721674382686615,\n",
       "  0.3721674382686615,\n",
       "  0.3721674382686615,\n",
       "  0.3721674382686615],\n",
       " 'loss': [0.6274194033813476,\n",
       "  0.6274193505096436,\n",
       "  0.6274192906951904,\n",
       "  0.6274192132568359,\n",
       "  0.6274191192626953],\n",
       " 'accuracy': [0.37258, 0.37258, 0.37258, 0.37258, 0.37258]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malstm_trained.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(malstm_trained.history['accuracy'])\n",
    "plt.plot(malstm_trained.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6185 ,  0.64254, -0.46552, ..., -0.27557,  0.30899,  0.48497],\n",
       "       [ 0.418  ,  0.24968, -0.41242, ..., -0.18411, -0.11514, -0.78581],\n",
       "       [ 0.48251,  0.87746, -0.23455, ..., -0.4112 ,  0.23625,  0.26451],\n",
       "       ...,\n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ],\n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ],\n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_a_vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7619  , -0.29773 ,  0.51396 , ...,  0.43088 , -0.22768 ,\n",
       "         0.4026  ],\n",
       "       [ 0.66979 , -0.21748 ,  0.17075 , ...,  0.38201 , -0.043277,\n",
       "         0.95    ],\n",
       "       [ 0.49861 , -0.12284 ,  0.44772 , ...,  0.26395 , -0.062214,\n",
       "         0.6292  ],\n",
       "       ...,\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_b_vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = layers.LSTM(50, unit_forget_bias=True, kernel_initializer='he_normal', kernel_regularizer='l2', name='lstm_layer')\n",
    "    \n",
    "left_input =Input(shape=(None, input_dim), name='input_1')\n",
    "left_output = lstm(left_input)\n",
    "    \n",
    "right_input =Input(shape=(None, input_dim), name='input_2')\n",
    "right_output = lstm(right_input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-59608f43994e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmanhattan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanhattan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1_distance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#merged = layers.concatenate(axis=-1)([left_output, right_output], mode = manhattan, output_shape = lambda x: (x[0][0],1), name='l1_distance')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "manhattan = lambda x: K.exp(-K.sum(K.abs(x[0]-x[1]), keepdims=True, axis=1))\n",
    "merged = layers.merge([left_output, right_output], mode = manhattan, output_shape = lambda x: (x[0][0],1), name='l1_distance')\n",
    "\n",
    "    \n",
    "#merged = layers.concatenate(axis=-1)([left_output, right_output], mode = manhattan, output_shape = lambda x: (x[0][0],1), name='l1_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
